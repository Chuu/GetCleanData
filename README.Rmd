Getting and Cleaning Data Course Project
--------------------------------------
This is my submission for the "Getting and Cleaning Data" course project.  Included within are the following items:

- README.md : The readme, likely the document you are reading now.
- run_analysis.R : Contains the core logic that transforms the source data set to the final data set and outputs tidyData.csv.  When this script is sourced it will create the two local variables `data` and `tidyData` to correspond with the original data set post-ETL, and the tidy data set submitted.
- codebook.md : The codebook for this data set
- tidyData.csv : The tidy data set, which can be read in via `read.csv("tidyData.csv")`

# Pre-requisites

- I am going to assume that the "UCI HAR Dataset" folder exists in your current working directory.  
- Besides that, all that is needed to run the `R` script is R itself.

# Note on Implementation

To ease grading, I've attempted to put each step of the data transformation process into its own function.  Below is a description of each step

## Merging the training and test sets to create one data set.
The first function called is `ReadAndMergeTables(...)` which takes as arguments the column names.  The column names are generated by reading in the headers as in via the `GetHeaders()` function, then lapplying the `CleanHeaderName()` function across the names to transform the original names to the names specified in our codebook.

## Extracts only the measurements on the mean and standard deviation for each measurement

The function `ExtractMeansStDevColNamesFilter` looks at each column name, and applies grepl to return a logical vector of the names that contain mean and standard deviation values.

## Uses descriptive activity names to name the activities in the data set

Note that our data set currently has no references to activities at all.  There is a function called `GetActivities(...)` which reads in the activities from the test and training data set, reads in the activity names from the `activity_labels.txt` file, and then returns a column with the correct activity label as a factor, where the factor values are descriptive.  We then just `cbind` this to our current data frame

## Appropriately labels the data set with descriptive variable names. 

We have actually already implicitly done this in previous steps.  In the first step we took care of transforming the original labels to descriptive labels according to our codebook, and the activity column was also given an appropriate name in the previous step.  When processing this data I felt that doing this as a separate step was not appropriate because the filtering we were doing thus far was based on these descriptive labels.

## Creates a second, independent tidy data set with the average of each variable for each activity and each subject. 

Given we have done all the above correctly, this step should be trivial, and it is.  The function `GenerateActivityMeans(...)` wraps the logic, which essentially is extracting the activity from the activity column then just applying the mean function across it.  The only tricky part is explicitly removing the Activity column in our result set.  We then write out the tidy data set to `tidyData.csv`.

# Final Tidy Data Set

For your convenience, the contents of `tidyData.csv` have been included inline in this project.

```{r, echo=TRUE}
tidyData <- read.csv("tidyData.csv")
kable(tidyData);
```
